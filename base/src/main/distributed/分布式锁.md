# 分布式锁
需要的原因:
1. 在程序开发过程中不得不考虑的就是并发问题。
2. 在java中对于同一个jvm而言，jdk已经提供了lock和同步等。但是在分布式情况下，往往存在多个进程对一些资源产生竞争关系，而这些进程往往在不同的机器上，这个时候jdk中提供的已经不能满足。
3. 分布式锁顾明思议就是可以满足分布式情况下的并发锁

1、 为了保证在分布式部署的应用集群中，同一个方法在同一操作只能被一台机器上的一个线程执行。
2. 只允许一个客户端操作共享资源

---
# 分布式锁使用场景
1. 场景1
![VQK6bt.png](https://s2.ax1x.com/2019/05/31/VQK6bt.png)

2. 场景2
```
某服务提供一组任务，A请求随机从任务组中获取一个任务；B请求随机从任务组中获取一个任务。
在理想的情况下，A从任务组中挑选一个任务，任务组删除该任务，B从剩下的的任务中再挑一个，任务组删除该任务。
同样的，在真实情况下，如果不做任何处理，可能会出现A和B挑中了同一个任务的情况。
```

---
# 分布式锁设计目标
可以保证在分布式部署的应用集群中，同一个方法在同一操作只能被一台机器上的一个线程执行。
+ 这把锁要是一把可重入锁（避免死锁）
+ 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）
+ 这把锁有高可用的获取锁和释放锁功能
+ 这把锁获取锁和释放锁的性能要好



---
# zookeeper
https://www.cnblogs.com/cc11001100/p/10269494.html

ZooKeeper 节点是有生命周期的，这取决于节点的类型。  
在 ZooKeeper 中，节点类型可以分为持久节点（PERSISTENT ）、临时节点（EPHEMERAL），以及时序节点（SEQUENTIAL ），具体在节点创建过程中，一般是组合使用，可以生成以下 4 种节点类型。  

## zk节点的含义
1. 持久节点（PERSISTENT）
> 所谓持久节点，是指在节点创建后，就一直存在，直到有删除操作来主动清除这个节点——不会因为创建该节点的客户端会话失效而消失。

2. 持久顺序节点（PERSISTENT_SEQUENTIAL）
> 这类节点的基本特性和上面的节点类型是一致的。额外的特性是，在ZK中，每个父节点会为他的第一级子节点维护一份时序，会记录每个子节点创建的先后顺序。
> 基于这个特性，在创建子节点的时候，可以设置这个属性，那么在创建节点过程中，ZK会自动为给定节点名加上一个数字后缀，作为新的节点名。
> 这个数字后缀的范围是整型的最大值。

3. 临时节点（EPHEMERAL）
> 和持久节点不同的是，临时节点的生命周期和客户端会话绑定。
> 也就是说，如果客户端会话失效，那么这个节点就会自动被清除掉。
> 注意，这里提到的是会话失效，而非连接断开。另外，在临时节点下面不能创建子节点。

4. 临时顺序节点（EPHEMERAL_SEQUENTIAL）
> 此节点是属于临时节点，不过带有顺序，客户端会话结束节点就消失。

5. 事件监听
> 在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。
> 当前zookeeper有如下四种事件：1）节点创建；2）节点删除；3）节点数据修改；4）子节点变更。


## 利用zk实现分布式锁
1. 建立一个节点，假如名为：lock 。节点类型为持久节点（PERSISTENT） 
2. 每当进程需要访问共享资源时，会调用分布式锁的lock()或tryLock()方法获得锁，这个时候会在第一步创建的lock节点下建立相应的顺序子节点，节点类型为临时顺序节点（EPHEMERAL_SEQUENTIAL），通过组成特定的名字name+lock+顺序号。 
3. 在建立子节点后，对lock下面的所有以name开头的子节点进行排序，判断刚刚建立的子节点顺序号是否是最小的节点，假如是最小节点，则获得该锁对资源进行访问。 
4. 假如不是该节点，就获得该节点的上一顺序节点，并给该节点是否存在注册监听事件。同时在这里阻塞。等待监听事件的发生，获得锁控制权。
5. 当调用完共享资源后，调用unlock（）方法，关闭zk，进而可以引发监听事件，释放该锁。 
6. 实现的分布式锁是严格的按照顺序访问的公平锁。

1. 以上步骤4中监听方式
    + 监听当前最小节点：非公平锁
    + 监听前一个节点：公平锁
2. 以上临时节点中存入，线程信息+获取数量->可重入的锁



> 始终只有最小顺序节点获取到了锁，按照请求顺序

1. 为什么采用临时顺序节点
  + 临时节点能够保证在故障的情况下锁也能被释放。
  + 假如客户端a当前创建的子节点为序号最小的节点，获得锁之后客户端所在机器宕机了，客户端没有主动删除子节点；
    + 如果创建的是永久的节点，那么这个锁永远不会释放，导致死锁；
    + 由于创建的是临时节点，客户端宕机后，过了一定时间zookeeper没有收到客户端的心跳包判断会话失效，将临时节点删除从而释放锁。

2. 获取子节点列表与设置监听这两步操作的原子性问题
> 假如客户端a对应子节点为/lock/lock-0000000000，客户端b对应子节点为/lock/lock-0000000001，
> 客户端b获取子节点列表时发现自己不是序号最小的，但是在设置监听器前客户端a完成业务流程删除了子节点/lock/lock-0000000000，
> 客户端b设置的监听器岂不是丢失了这个事件从而导致永远等待了？

回答:因为zookeeper提供的API中设置监听器的操作与读操作是原子执行的，也就是说在读子节点列表时同时设置监听器，保证不会丢失事件。  

3. zk分布式锁优化
> 假如当前有1000个节点在等待锁，如果获得锁的客户端释放锁时，这1000个客户端都会被唤醒，这种情况称为“羊群效应”；
> 在这种羊群效应中，zookeeper需要通知1000个客户端，这会阻塞其他的操作，最好的情况应该只唤醒新的最小节点对应的客户端。
> 所以在设置事件监听时，每个客户端应该对刚好在它之前的子节点设置事件监听，例如子节点列表为/lock/lock-0000000000、/lock/lock-0000000001、/lock/lock-0000000002，序号为1的客户端监听序号为0的子节点删除消息，序号为2的监听序号为1的子节点删除消息。

4. 这样实现的分布式锁，是一个公平锁，按照顺序进行获取。



### 问题
1. 创建节点时，如果节点编号不是最小的，需要监听编号比自己小的节点，如果监听的节点挂了，那后面的节点是不是都不会收到消息了呢？
  + 节点挂了，等心跳超时的时候，这个临时节点会删除。删除的操作会通知后面的节点的




# redis

## 利用redis实现的可靠性
1. 互斥性。在任意时刻，只有一个客户端能持有锁。
2. 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
3. 具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
4. 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。

1. 当前涉及为：非公平的可重入锁
2. 如果设置某个集合，并在释放锁的时候去唤醒哪些没获取到锁的线程->公平锁

## 加锁
```java
public class RedisTool {

    private static final String LOCK_SUCCESS = "OK";
    private static final String SET_IF_NOT_EXIST = "NX";
    private static final String SET_WITH_EXPIRE_TIME = "PX";

    /**
     * 尝试获取分布式锁
     * @param jedis Redis客户端
     * @param lockKey 锁
     * @param requestId 请求标识
     * @param expireTime 超期时间
     * @return 是否获取成功
     */
    public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) {

        String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);

        if (LOCK_SUCCESS.equals(result)) {
            return true;
        }
        return false;

    }
}
```
1. 可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参：
    + 第一个为key，我们使用key来当锁，因为key是唯一的。
    + 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。
    + 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作；
    + 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。
    + 第五个为time，与第四个参数相呼应，代表key的过期时间。
 
2. 总的来说，执行上面的set()方法就只会导致两种结果：
   + 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。
   + 已有锁存在，不做任何操作。 

3. 我们的加锁代码满足我们可靠性里描述的三个条件
   + 首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。
   + 其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。
   + 最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。

## 解锁
```java
public class RedisTool {

    private static final Long RELEASE_SUCCESS = 1L;

    /**
     * 释放分布式锁
     * @param jedis Redis客户端
     * @param lockKey 锁
     * @param requestId 请求标识
     * @return 是否释放成功
     */
    public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) {

        String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
        Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));

        if (RELEASE_SUCCESS.equals(result)) {
            return true;
        }
        return false;

    }

}
```
解释：  
1. 第一行代码，我们写了一个简单的Lua脚本代码
2. 第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。

rua代码功能：  
1. 首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）
2. 使用rua是因为要确保上述操作是原子性的
3. 简单来说，就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。



## 资料
1. https://wudashan.cn/2017/10/23/Redis-Distributed-Lock-Implement/
2. https://crossoverjie.top/2018/03/29/distributed-lock/distributed-lock-redis/
3. https://juejin.im/post/5bf3f15851882526a643e207#heading-3


# 数据库
## 利用锁表数据
1. 利用mysql的隔离性：唯一索引
  + 创建一张锁表，
  + 当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。
  
2. 利用锁表存在的问题
    + 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。
    > 数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。
    + 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。
    > 没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。
    + 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。
    > 非阻塞的？搞一个while循环，直到insert成功再返回成功。
    + 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。
    > 非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。

## 利用排他锁 for update
1. 利用select … where … for update 排他锁
   + 其他附加功能与实现一基本一致，这里需要注意的是，如果查询条件为“where name=lock ”，name字段必须要走索引，否则会锁表。
   + 有些情况下，比如表不大，mysql优化器会不走这个索引，导致锁表问题。

2. 利用排他锁存在的问题
   + 有些情况下，比如表不大，mysql优化器会不走这个索引，导致锁表问题
   + 就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆


## 利用version 乐观锁
1. 实现方式 ，表内数据添加version字段
   + 查询时候，查询出version版本
   + 每次修改时候，需要根据oldversion版本进行更新，且修改完毕后，升级version
   

## 基于数据库总结
1. 数据库实现分布式锁的优点
    + 直接借助数据库，容易理解。

2. 数据库实现分布式锁的缺点
    + 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。
    + 操作数据库需要一定的开销，性能问题需要考虑。
    + 使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。



# 分布式锁比较

## 数据库分布式锁实现
1. 缺点
   + db操作性能较差，并且有锁表的风险
   + 非阻塞操作失败后，需要轮询，占用cpu资源;
   + 长时间不commit或者长时间轮询，可能会占用较多连接资源
   

## Redis(缓存)分布式锁实现
1. 缺点：
   + 锁删除失败 过期时间不好控制
   + 非阻塞，操作失败后，需要轮询，占用cpu资源;
   
## ZK分布式锁实现
1. 缺点：
   + 性能不如redis实现，主要原因是写操作（获取锁释放锁）都需要在Leader上执行，然后同步到follower。

## 总结
1. ZooKeeper有较好的性能和可靠性。
2. 从理解的难易程度角度（从低到高）数据库 > 缓存 > Zookeeper
3. 从实现的复杂性角度（从低到高）Zookeeper >= 缓存 > 数据库
4. 从性能角度（从高到低）缓存 > Zookeeper >= 数据库
5. 从可靠性角度（从高到低）Zookeeper > 缓存 > 数据库

1. redis分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能
2. zk分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小
3. 如果是redis获取锁的那个客户端bug了或者挂了，那么只能等待超时时间之后才能释放锁；而zk的话，因为创建的是临时znode，只要客户端挂了，znode就没了，此时就自动释放锁

---
# 扩展RedLock锁
## 原由
1. redis的分布式锁，适用于单机redis
    + set(key,valye,nx,px,time)进行获取锁
    + 利用lua脚本的(get,del)原子操作进行释放锁

2. 当集群时，加入是主从redis集群(master-Slave)
    + Client1从Master1中获取到了资源锁
    + 此时Master1突然宕机
    + 由于主从异步复制，Slave还没接收到同步数据，且此时由于Master1宕机，则failover后升级成Mater2
    + Client2从新的master中获取到新的资源锁
    + 则此时，Client1和Client2同时获取到一个资源的锁，则不符合安全性

## RedLock锁
分布式锁的算法Redlock，它基于N个完全独立的Redis节点。  
但是此锁方法需要redis节点时间一致。

### 获取锁操作
1. 获取当前时间（毫秒数）。
2. 按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。
3. 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（>= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。
4. 如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。
5. 如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的Redis Lua脚本）。

### 释放锁
1. 客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。
2. 为什么向没有锁成功的节点进行释放锁的操作
   + 即使当时向某个节点获取锁没有成功，在释放锁的时候也不应该漏掉这个节点。
   + 设想这样一种情况，客户端发给某个Redis节点的获取锁的请求成功到达了该Redis节点，这个节点也成功执行了SET操作，但是它返回给客户端的响应包却丢失了。
   + 这在客户端看来，获取锁的请求由于超时而失败了，但在Redis这边看来，加锁已经成功了。

### 回归集群问题
1. 由于多数redis节点获取到锁了(>N/2+1)
2. 当某台Master挂点之后，Slave升级为新的Master时
3. 其他Client获取锁时候，由于多数redis已经有对应的资源锁了，则将获取失败

### 节点崩溃重启问题
1. 假设一共有5个Redis节点：A, B, C, D, E。
2. 客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。
3. 节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。
4. 节点C重启后，客户端2锁住了C, D, E，获取锁成功。
5. 这样客户端1和客户端2 还是拥有了共同的资源锁。

**延迟重启：** 延迟重启：这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。 

---

# 分布式id
## 分布式ID的特性
1. 唯一性：确保生成的ID是全网唯一的。
2. 有序递增性：确保生成的ID是对于某个用户或者业务是按一定的数字有序递增的。
3. 高可用性：确保任何时候都能正确的生成ID。
4. 带时间：ID里面包含时间，一眼扫过去就知道哪天的交易。

## 分布式ID的生成方案
1. UUID
   + 算法的核心思想是结合机器的网卡、当地时间、一个随记数来生成UUID。
   + 优点：本地生成，生成简单，性能好，没有高可用风险
   + 缺点：长度过长，存储冗余，且无序不可读，查询效率低

2. 数据库自增ID
   + 使用数据库的id自增策略，如 MySQL 的 auto_increment。并且可以使用两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。
   + 优点：数据库生成的ID绝对有序，高可用实现方式简单
   + 缺点：需要独立部署数据库实例，成本高，有性能瓶颈
   
3. 批量生成ID
   + 一次按需批量生成多个ID，每次生成都需要访问数据库，将数据库修改为最大的ID值，并在内存中记录当前值及最大值。
   + 优点：避免了每次生成ID都要访问数据库并带来压力，提高性能
   + 缺点：属于本地生成策略，存在单点故障，服务重启造成ID不连续

4. Redis生成ID
   + Redis的所有命令操作都是单线程的，本身提供像 incr 和 increby 这样的自增原子命令，所以能保证生成的 ID 肯定是唯一有序的。
   + 优点：不依赖于数据库，灵活方便，且性能优于数据库；数字ID天然排序，对分页或者需要排序的结果很有帮助。
   + 缺点：如果系统中没有Redis，还需要引入新的组件，增加系统复杂度；需要编码和配置的工作量比较大。

5. 
